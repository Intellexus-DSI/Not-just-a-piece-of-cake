{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ba301b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: together in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (1.5.17)\n",
      "Requirement already satisfied: datasets in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (3.6.0)\n",
      "Requirement already satisfied: transformers in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (4.53.0)\n",
      "Requirement already satisfied: tqdm in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (4.67.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from together) (3.12.11)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from together) (8.1.8)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.1.3 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from together) (0.2.2)\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from together) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from together) (2.3.0)\n",
      "Requirement already satisfied: pillow<12.0.0,>=11.1.0 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from together) (11.2.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from together) (2.11.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from together) (2.32.3)\n",
      "Requirement already satisfied: rich<15.0.0,>=13.8.1 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from together) (14.0.0)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from together) (0.9.0)\n",
      "Requirement already satisfied: typer<0.16,>=0.9 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from together) (0.15.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.6.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.20.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.6.3->together) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.6.3->together) (4.14.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.6.3->together) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.31.0->together) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.31.0->together) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.31.0->together) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.31.0->together) (2025.4.26)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from rich<15.0.0,>=13.8.1->together) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from rich<15.0.0,>=13.8.1->together) (2.19.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from typer<0.16,>=0.9->together) (1.5.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from datasets) (0.31.1)\n",
      "Requirement already satisfied: packaging in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.8.1->together) (0.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ofrihefetz/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U together datasets transformers tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de153be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/ofrihefetz/cross-lingual-idioms-1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import ast\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from together.utils import check_file\n",
    "from together import Together\n",
    "\n",
    "# Find the real project root\n",
    "current_dir = Path.cwd()\n",
    "project_root = current_dir.parent  # because you're in \"gen_fine_tuning\", and project root is one level up\n",
    "\n",
    "print(\"Project root:\", project_root)\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.mult_lang import read_bio_json, read_bio_tsv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfdaf0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGE_CONFIG = {\n",
    "    \"turkish\": {\"format\": \"json\", \"source\": \"dodiom\"},\n",
    "    \"japanese\": {\"format\": \"json\", \"source\": \"OpenMWE_sub\"},\n",
    "    \"english\": {\"format\": \"tsv\", \"source\": \"id10m\"},\n",
    "    \"french\": {\"format\": \"tsv\", \"source\": \"id10m\"},\n",
    "    \"german\": {\"format\": \"tsv\", \"source\": \"id10m\"},\n",
    "    \"italian\": {\"format\": \"tsv\", \"source\": \"id10m\"},\n",
    "    \"spanish\": {\"format\": \"tsv\", \"source\": \"id10m\"},\n",
    "    \"dutch\": {\"format\": \"tsv\", \"source\": \"id10m\"},\n",
    "    \"chinese\": {\"format\": \"tsv\", \"source\": \"id10m\"},\n",
    "    \"polish\": {\"format\": \"tsv\", \"source\": \"id10m\"},\n",
    "    \"portuguese\": {\"format\": \"tsv\", \"source\": \"id10m\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb7bae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_langs = [\"turkish\", \"japanese\", \"english\", \"french\", \"german\", \"italian\", \"spanish\", \"dutch\", \"chinese\", \"polish\", \"portuguese\"]\n",
    "val_langs = [\"english\", \"french\", \"german\", \"italian\", \"spanish\", \"dutch\", \"chinese\", \"polish\", \"portuguese\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f18061",
   "metadata": {},
   "source": [
    "## saving the jsonl file in the right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c894ac0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Automatically detect the project root (one level up from current script)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m project_root = os.path.abspath(os.path.join(os.path.dirname(\u001b[34;43m__file__\u001b[39;49m), \u001b[33m\"\u001b[39m\u001b[33m..\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Automatically detect the project root (one level up from current script)\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a43dc8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_CONFIG = {\n",
    "    \"dodiom\": {\n",
    "        \"train_dir\": os.path.join(project_root, \"data/dodiom/{lang}/train.json\"),\n",
    "        \"test_dir\": os.path.join(project_root, \"data/dodiom/{lang}/test.json\"),\n",
    "        \"val_dir\": None\n",
    "    },\n",
    "    \"id10m\": {\n",
    "        \"train_dir\": os.path.join(project_root, \"data/id10m/trainset/{lang}.tsv\"),\n",
    "        \"test_dir\": os.path.join(project_root, \"data/id10m/testset/{lang}.tsv\"),\n",
    "        \"val_dir\": os.path.join(project_root, \"data/id10m/devset/{lang}.tsv\")\n",
    "    },\n",
    "    \"open_mwe\": {\n",
    "        \"train_dir\": os.path.join(project_root, \"data/OpenMWE_sub/train.json\"),\n",
    "        \"test_dir\": os.path.join(project_root, \"data/OpenMWE_sub/test.json\"),\n",
    "        \"val_dir\": None\n",
    "    },\n",
    "    \"magpie\": {\n",
    "        \"train_dir\": os.path.join(project_root, \"data/magpie/MAGPIE_train_processed.jsonl\"),\n",
    "        \"test_dir\": os.path.join(project_root, \"data/magpie/MAGPIE_test_processed_mini.jsonl\"),\n",
    "        \"val_dir\": None\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9caef92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import numpy as np\n",
    "def get_data(lang: str, task: str) -> dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Load train, test, and validation data for a given language and task.\n",
    "    Returns a dictionary: {'train': df, 'test': df, 'validation': df}\n",
    "    \"\"\"\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    config = TASK_CONFIG.get(task)\n",
    "    if config is None:\n",
    "        raise ValueError(f\"No task configuration found for task='{task}'.\")\n",
    "    \n",
    "    if task == \"open_mwe\":\n",
    "        assert lang == \"japanese\", f\"âŒ open_mwe only supports lang='japanese', but got lang='{lang}'\"\n",
    "    \n",
    "    \n",
    "\n",
    "    def load_json_lines(file_path: str) -> pd.DataFrame:\n",
    "        if not os.path.exists(file_path):\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        if task in {\"open_mwe\", \"id10m\"}:\n",
    "            return read_bio_json(file_path)  # uses full JSON list structure\n",
    "        elif task in {\"magpie\",\"dodiom\"}:\n",
    "            # Magpie is JSONL (one JSON per line)\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = [json.loads(line) for line in f if line.strip()]\n",
    "            return pd.DataFrame(data)\n",
    "        else:\n",
    "            raise ValueError(f\"No JSON loader defined for task={task}\")\n",
    "\n",
    "    def load_tsv(file_path: str) -> pd.DataFrame:\n",
    "        if not os.path.exists(file_path):\n",
    "            return pd.DataFrame()\n",
    "        return read_bio_tsv(file_path)  # Assuming this function exists\n",
    "\n",
    "    def resolve_path(template: str | None) -> str | None:\n",
    "        if template is None:\n",
    "            return None\n",
    "        return template.format(lang=lang) if \"{lang}\" in template else template\n",
    "\n",
    "    def load_split(split: str) -> pd.DataFrame:\n",
    "        path = resolve_path(config.get(f\"{split}_dir\"))\n",
    "        if path is None or not os.path.exists(path):\n",
    "            return pd.DataFrame()\n",
    "        if path.endswith(\".json\") or path.endswith(\".jsonl\"):\n",
    "            return load_json_lines(path)\n",
    "        elif path.endswith(\".tsv\"):\n",
    "            return load_tsv(path)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file type: {path}\")\n",
    "\n",
    "    # Load all splits\n",
    "    data = {\n",
    "        \"train\": load_split(\"train\"),\n",
    "        \"test\": load_split(\"test\"),\n",
    "        \"validation\": load_split(\"val\")\n",
    "    }\n",
    "\n",
    "    # Print summary\n",
    "    for split, df in data.items():\n",
    "        size = df.shape if not df.empty else \"empty\"\n",
    "        print(f\"âœ… Loaded {split} for task='{task}', lang='{lang}': {size}\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b245d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# SYSTEM_MESSAGE = \"\"\"You are a professional linguist specializing in figurative language and your task is to analyse sentences that may contain an idiom, also known as an idiomatic expression. \n",
    "# This is a definition of idiom: 'A phrase, expression, or group of words that has a meaning different from the individual meanings of the words themselves, and employed to convey ideas in a non-literal or metaphorical manner'.\n",
    "# Mark idioms only when their usage in the context is idiomatic/figurative and let literal meanings remain unmarked.\"\"\"\n",
    "\n",
    "\n",
    "# USER_PROMPT_TEMPLATE = \"\"\"You are given one sentence in {language}, you are an expert of this language.\n",
    "# If detected, write the idioms exactly as they are in the sentence, without any changes. Only answer in JSON.\\n\n",
    "# Sentence:{sentence}\\n \"\"\"\n",
    "\n",
    "SYSTEM_MESSAGE = \"\"\"You are a professional linguist specializing in figurative language and your task is to analyse sentences that may contain an idiom, also known as an idiomatic expression. \n",
    "This is a definition of idiom: 'A phrase, expression, or group of words that has a meaning different from the individual meanings of the words themselves, and employed to convey ideas in a non-literal or metaphorical manner'.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"You are given one sentence in {language}, you are an expert of this language.\n",
    "Your task is to identify idioms **only if** they are used in an **idiomatic or figurative sense**. If the usage is literal, do not mark it.\n",
    "- Output only the idioms that appear **exactly** as they are in the sentence, without any changes. Return the answer **in JSON format only**.\\n\n",
    "Sentence:{sentence}\\n \"\"\"\n",
    "\n",
    "def row_to_chat_format(row):\n",
    "    \"\"\"\n",
    "    Convert a single row of the dataset into Together AI conversational fine-tuning format.\n",
    "    \"\"\"\n",
    "    language = row[\"language\"]\n",
    "    sentence = row[\"sentence\"]\n",
    "    idioms = row[\"true_idioms\"]\n",
    "\n",
    "    user_message = USER_PROMPT_TEMPLATE.format(language=language, sentence=sentence)\n",
    "    assistant_response = json.dumps(idioms, ensure_ascii=False)\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "            {\"role\": \"user\", \"content\": user_message},\n",
    "            {\"role\": \"assistant\", \"content\": assistant_response}\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c775c703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_file(language, task, data_type):\n",
    "    df = get_data(language,task)\n",
    "    seed = 42\n",
    "    df = df[\"train\"]\n",
    "    with_idiom = df[df[\"true_idioms\"].apply(lambda x: len(x) > 0)]\n",
    "    without_idiom = df[df[\"true_idioms\"].apply(lambda x: len(x) == 0)]\n",
    "    \n",
    "    if language == \"turkish\" and task == \"dodiom\":\n",
    "            with_idiom = df[df[\"category\"].apply(lambda x: x == \"idiom\")]\n",
    "            without_idiom = df[df[\"category\"].apply(lambda x: x == \"nonidiom\")]\n",
    "\n",
    "    \n",
    "    if data_type == \"train\":\n",
    "        # Compute counts\n",
    "        n_total = 1500\n",
    "        percent_with_idiom = 0.27662410759249934\n",
    "        n_with = round(n_total * percent_with_idiom)   # â‰ˆ216\n",
    "        n_without = n_total - n_with \n",
    "    \n",
    "    else: \n",
    "        n_total = 1 #150\n",
    "        percent_with_idiom = 0 #0.19736842105263158\n",
    "        n_with = round(n_total * percent_with_idiom)  \n",
    "        n_without = n_total - n_with \n",
    "    \n",
    "    # Sample\n",
    "    sample_with_idiom = with_idiom.sample(n=n_with, random_state=42)\n",
    "    sample_without_idiom = without_idiom.sample(n=n_without, random_state=42)\n",
    "    \n",
    "    if language == \"turkish\" and task == \"dodiom\":\n",
    "        sample_without_idiom[\"true_idioms\"] = sample_without_idiom[\"true_idioms\"].apply(lambda _: [])\n",
    "\n",
    "    \n",
    "    # Combine and shuffle\n",
    "    final_sample = pd.concat([sample_with_idiom, sample_without_idiom]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    final_sample[\"language\"] = language\n",
    "    massage_df = final_sample.apply(row_to_chat_format, axis=1)\n",
    "\n",
    "    # Create the output folder if it doesnâ€™t exist\n",
    "    output_folder = Path(\"jsonl_data\")\n",
    "    output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Build the full path\n",
    "    output_path = output_folder / f\"{language}_{n_total}_{seed}_{data_type}.jsonl\"\n",
    "\n",
    "    # Save the file\n",
    "    massage_df.to_json(output_path, orient=\"records\", lines=True)\n",
    "\n",
    "    print(f\"âœ… Saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36e4833d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded train for task='id10m', lang='english': (33757, 5)\n",
      "âœ… Loaded test for task='id10m', lang='english': (200, 5)\n",
      "âœ… Loaded validation for task='id10m', lang='english': (3724, 5)\n",
      "âœ… Saved to jsonl_data/english_1500_42_train.jsonl\n"
     ]
    }
   ],
   "source": [
    "get_json_file(\"english\", \"id10m\", \"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9ec6fd",
   "metadata": {},
   "source": [
    "## uplode the files to together AI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "522d0ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded API key from: /Users/ofrihefetz/cross-lingual-idioms-1/keys.yaml\n"
     ]
    }
   ],
   "source": [
    "# get the key to together API from keys.yaml \n",
    "current_dir = Path.cwd()\n",
    "while current_dir != current_dir.parent:  # stop at root\n",
    "    if (current_dir / \"keys.yaml\").exists():\n",
    "        keys_file = current_dir / \"keys.yaml\"\n",
    "        break\n",
    "    current_dir = current_dir.parent\n",
    "else:\n",
    "    raise FileNotFoundError(\"Could not find keys.yaml in any parent directory\")\n",
    "\n",
    "# Load the keys\n",
    "with open(keys_file, \"r\") as f:\n",
    "    keys = yaml.safe_load(f)\n",
    "\n",
    "TOGETHER_API_KEY = keys[\"TOGETHER_API_KEY\"]\n",
    "\n",
    "print(f\"âœ… Loaded API key from: {keys_file}\")\n",
    "client = Together(api_key=TOGETHER_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43fdbfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"is_check_passed\": true,\n",
      "  \"message\": \"Checks passed\",\n",
      "  \"found\": true,\n",
      "  \"file_size\": 1562519,\n",
      "  \"utf8\": true,\n",
      "  \"line_type\": true,\n",
      "  \"text_field\": true,\n",
      "  \"key_value\": true,\n",
      "  \"has_min_samples\": true,\n",
      "  \"num_samples\": 1500,\n",
      "  \"load_json\": true,\n",
      "  \"filetype\": \"jsonl\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading file english_1500_42_train.jsonl: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.56M/1.56M [00:01<00:00, 860kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-468fa8c0-3d0a-451f-861e-c922d7f7b5fa\n"
     ]
    }
   ],
   "source": [
    "# choose a file to check \n",
    "file = \"/Users/ofrihefetz/cross-lingual-idioms-1/gen_fine_tuning/jsonl_data/english_1500_42_train.jsonl\"\n",
    "sft_report = check_file(file)\n",
    "print(json.dumps(sft_report, indent=2))\n",
    "assert sft_report[\"is_check_passed\"] == True\n",
    "\n",
    "# Upload the data to Together\n",
    "train_file_resp = client.files.upload(file, check=True)\n",
    "print(train_file_resp.id)  # Save this ID for starting your fine-tuning job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91578c73",
   "metadata": {},
   "source": [
    "## Creating end point for FT modles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969b6c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Endpoint created!\n",
      "ID: endpoint-72738d88-6b49-4a7a-a345-1a25518709d1\n",
      "Status: PENDING\n"
     ]
    }
   ],
   "source": [
    "response = client.endpoints.create(\n",
    "    display_name=\"Gemma-3-12B-Inference\",\n",
    "    model=\"kfirbar/gemma-3-12b-it-ADDTOEXPNAME-f399f126\",  # Replace with your fine-tuned model\n",
    "    hardware=\"2x_nvidia_h100_80gb_sxm\",                    # âœ… confirmed hardware\n",
    "    min_replicas= 1,\n",
    "    max_replicas=1\n",
    ")\n",
    "\n",
    "print(\"âœ… Endpoint created!\")\n",
    "print(\"ID:\", response.id)\n",
    "print(\"Status:\", response.state)\n",
    "print(\"Endpint name:\", response.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d8dd789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DedicatedEndpoint(object='endpoint', id='endpoint-72738d88-6b49-4a7a-a345-1a25518709d1', name='kfirbar/gemma-3-12b-it-ADDTOEXPNAME-f399f126-15c6af46', model='kfirbar/gemma-3-12b-it-ADDTOEXPNAME-f399f126', type='dedicated', owner='kfirbar', state='PENDING', created_at=datetime.datetime(2025, 6, 27, 14, 37, 30, 356000, tzinfo=TzInfo(UTC)), display_name='Gemma-3-12B-Inference', hardware='2x_nvidia_h100_80gb_sxm', autoscaling=Autoscaling(min_replicas=1, max_replicas=1))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c93c3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DedicatedEndpoint(object='endpoint', id='endpoint-72738d88-6b49-4a7a-a345-1a25518709d1', name='kfirbar/gemma-3-12b-it-ADDTOEXPNAME-f399f126-15c6af46', model='kfirbar/gemma-3-12b-it-ADDTOEXPNAME-f399f126', type='dedicated', owner='kfirbar', state='STOPPED', created_at=datetime.datetime(2025, 6, 27, 14, 37, 30, 356000, tzinfo=TzInfo(UTC)), display_name='Gemma-3-12B-Inference', hardware='2x_nvidia_h100_80gb_sxm', autoscaling=Autoscaling(min_replicas=1, max_replicas=1))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# status of the endpoint\n",
    "client.endpoints.get(endpoint_id='endpoint-72738d88-6b49-4a7a-a345-1a25518709d1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64d24290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DedicatedEndpoint(object='endpoint', id='endpoint-72738d88-6b49-4a7a-a345-1a25518709d1', name='kfirbar/gemma-3-12b-it-ADDTOEXPNAME-f399f126-15c6af46', model='kfirbar/gemma-3-12b-it-ADDTOEXPNAME-f399f126', type='dedicated', owner='kfirbar', state='PENDING', created_at=datetime.datetime(2025, 6, 27, 14, 37, 30, 356000, tzinfo=TzInfo(UTC)), display_name='Gemma-3-12B-Inference', hardware='2x_nvidia_h100_80gb_sxm', autoscaling=Autoscaling(min_replicas=1, max_replicas=1))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start the endpoint\n",
    "client.endpoints.update(endpoint_id='endpoint-72738d88-6b49-4a7a-a345-1a25518709d1', state='STARTED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b41bfb2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DedicatedEndpoint(object='endpoint', id='endpoint-72738d88-6b49-4a7a-a345-1a25518709d1', name='kfirbar/gemma-3-12b-it-ADDTOEXPNAME-f399f126-15c6af46', model='kfirbar/gemma-3-12b-it-ADDTOEXPNAME-f399f126', type='dedicated', owner='kfirbar', state='STOPPING', created_at=datetime.datetime(2025, 6, 27, 14, 37, 30, 356000, tzinfo=TzInfo(UTC)), display_name='Gemma-3-12B-Inference', hardware='2x_nvidia_h100_80gb_sxm', autoscaling=Autoscaling(min_replicas=1, max_replicas=1))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stop the endpoint\n",
    "client.endpoints.update(endpoint_id='endpoint-72738d88-6b49-4a7a-a345-1a25518709d1', state='STOPPED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdea5a9f",
   "metadata": {},
   "source": [
    "## create end point for not the FT model! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43f3a9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Endpoint created!\n",
      "ID: endpoint-2a1507bb-bd80-44a5-9cce-6bec28797648\n",
      "Status: PENDING\n",
      "Endpint name: kfirbar/Qwen/Qwen3-0.6B-0abdf1c5\n"
     ]
    }
   ],
   "source": [
    "response = client.endpoints.create(\n",
    "    display_name=\"kfirbar/Qwen/Qwen3-0.6B\",\n",
    "    model=\"Qwen/Qwen3-0.6B\",  # Replace with your fine-tuned model\n",
    "    hardware=\"1x_nvidia_h100_80gb_sxm\",                    # âœ… confirmed hardware\n",
    "    min_replicas= 1,\n",
    "    max_replicas=1\n",
    ")\n",
    "\n",
    "print(\"âœ… Endpoint created!\")\n",
    "print(\"ID:\", response.id)\n",
    "print(\"Status:\", response.state)\n",
    "print(\"Endpint name:\", response.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50edfa12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DedicatedEndpoint(object='endpoint', id='endpoint-b3a688d0-7bdf-4cd7-afde-c0b79569f1ae', name='kfirbar/Qwen/Qwen3-4B-e24b8b92', model='Qwen/Qwen3-4B', type='dedicated', owner='kfirbar', state='PENDING', created_at=datetime.datetime(2025, 7, 9, 8, 35, 41, 850000, tzinfo=TzInfo(UTC)), display_name='kfirbar/Qwen/Qwen3-4B', hardware='1x_nvidia_h100_80gb_sxm', autoscaling=Autoscaling(min_replicas=1, max_replicas=1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start the endpoint\n",
    "client.endpoints.update(endpoint_id='endpoint-b3a688d0-7bdf-4cd7-afde-c0b79569f1ae', state='STARTED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f182ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DedicatedEndpoint(object='endpoint', id='endpoint-2a1507bb-bd80-44a5-9cce-6bec28797648', name='kfirbar/Qwen/Qwen3-0.6B-0abdf1c5', model='Qwen/Qwen3-0.6B', type='dedicated', owner='kfirbar', state='STARTED', created_at=datetime.datetime(2025, 7, 9, 9, 6, 26, 634000, tzinfo=TzInfo(UTC)), display_name='kfirbar/Qwen/Qwen3-0.6B', hardware='1x_nvidia_h100_80gb_sxm', autoscaling=Autoscaling(min_replicas=1, max_replicas=1))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.endpoints.get(endpoint_id='endpoint-2a1507bb-bd80-44a5-9cce-6bec28797648')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15c812bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DedicatedEndpoint(object='endpoint', id='endpoint-2a1507bb-bd80-44a5-9cce-6bec28797648', name='kfirbar/Qwen/Qwen3-0.6B-0abdf1c5', model='Qwen/Qwen3-0.6B', type='dedicated', owner='kfirbar', state='STOPPING', created_at=datetime.datetime(2025, 7, 9, 9, 6, 26, 634000, tzinfo=TzInfo(UTC)), display_name='kfirbar/Qwen/Qwen3-0.6B', hardware='1x_nvidia_h100_80gb_sxm', autoscaling=Autoscaling(min_replicas=1, max_replicas=1))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stop the endpoint\n",
    "client.endpoints.update(endpoint_id='endpoint-2a1507bb-bd80-44a5-9cce-6bec28797648', state='STOPPED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071c555d",
   "metadata": {},
   "source": [
    "## change the parsing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1c73adcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Loaded 200 responses. Showing first 5:\n",
      "\n",
      "\n",
      "====== Example 1 ======\n",
      "\n",
      "ðŸ“ Sentence: A rock has broken the ice covering a lake.\n",
      "\n",
      "ðŸ”¹ Raw model output:\n",
      "```json\n",
      "{\n",
      "  \"idioms\": []\n",
      "}\n",
      "```\n",
      "\n",
      "âœ… Parsed idioms: []\n",
      "\n",
      "ðŸŸ¦ Token-by-token comparison:\n",
      "Token           Gold         Predicted   \n",
      "---------------------------------------------\n",
      "A               O            O           \n",
      "rock            O            O           \n",
      "has             O            O           \n",
      "broken          O            O           \n",
      "the             O            O           \n",
      "ice             O            O           \n",
      "covering        O            O           \n",
      "a               O            O           \n",
      "lake            O            O           \n",
      ".               O            O           \n",
      "\n",
      "====== Example 2 ======\n",
      "\n",
      "ðŸ“ Sentence: The ship broke the ice all the way.\n",
      "\n",
      "ðŸ”¹ Raw model output:\n",
      "```json\n",
      "{\n",
      "  \"idioms\": [\n",
      "    \"broke the ice\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "âœ… Parsed idioms: ['broke the ice']\n",
      "\n",
      "ðŸŸ¦ Token-by-token comparison:\n",
      "Token           Gold         Predicted   \n",
      "---------------------------------------------\n",
      "The             O            O           \n",
      "ship            O            O           \n",
      "broke           O            B-IDIOM     \n",
      "the             O            I-IDIOM     \n",
      "ice             O            I-IDIOM     \n",
      "all             O            O           \n",
      "the             O            O           \n",
      "way             O            O           \n",
      ".               O            O           \n",
      "\n",
      "====== Example 3 ======\n",
      "\n",
      "ðŸ“ Sentence: This is a perfect way to break the ice and start the conversation.\n",
      "\n",
      "ðŸ”¹ Raw model output:\n",
      "```json\n",
      "{\n",
      "  \"idioms\": [\n",
      "    \"break the ice\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "âœ… Parsed idioms: ['break the ice']\n",
      "\n",
      "ðŸŸ¦ Token-by-token comparison:\n",
      "Token           Gold         Predicted   \n",
      "---------------------------------------------\n",
      "This            O            O           \n",
      "is              O            O           \n",
      "a               O            O           \n",
      "perfect         O            O           \n",
      "way             O            O           \n",
      "to              O            O           \n",
      "break           B-IDIOM      B-IDIOM     \n",
      "the             I-IDIOM      I-IDIOM     \n",
      "ice             I-IDIOM      I-IDIOM     \n",
      "and             O            O           \n",
      "start           O            O           \n",
      "the             O            O           \n",
      "conversation    O            O           \n",
      ".               O            O           \n",
      "\n",
      "====== Example 4 ======\n",
      "\n",
      "ðŸ“ Sentence: The bullet hit thebook in his pocket.\n",
      "\n",
      "ðŸ”¹ Raw model output:\n",
      "```json\n",
      "{\n",
      "  \"idioms\": []\n",
      "}\n",
      "```\n",
      "\n",
      "âœ… Parsed idioms: []\n",
      "\n",
      "ðŸŸ¦ Token-by-token comparison:\n",
      "Token           Gold         Predicted   \n",
      "---------------------------------------------\n",
      "The             O            O           \n",
      "bullet          O            O           \n",
      "hit             O            O           \n",
      "thebook         O            O           \n",
      "in              O            O           \n",
      "his             O            O           \n",
      "pocket          O            O           \n",
      ".               O            O           \n",
      "\n",
      "====== Example 5 ======\n",
      "\n",
      "ðŸ“ Sentence: The victim was stabbed in the back by a criminal.\n",
      "\n",
      "ðŸ”¹ Raw model output:\n",
      "```json\n",
      "{\n",
      "  \"idioms\": [\n",
      "    \"stabbed in the back\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "âœ… Parsed idioms: ['stabbed in the back']\n",
      "\n",
      "ðŸŸ¦ Token-by-token comparison:\n",
      "Token           Gold         Predicted   \n",
      "---------------------------------------------\n",
      "The             O            O           \n",
      "victim          O            O           \n",
      "was             O            O           \n",
      "stabbed         O            B-IDIOM     \n",
      "in              O            I-IDIOM     \n",
      "the             O            I-IDIOM     \n",
      "back            O            I-IDIOM     \n",
      "by              O            O           \n",
      "a               O            O           \n",
      "criminal        O            O           \n",
      ".               O            O           \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from pprint import pprint\n",
    "from src.gen_utils import idioms_list_to_IOB  # Adjust import if needed\n",
    "\n",
    "# === CONFIG ===\n",
    "RESPONSES_PATH = \"logs/gemma-3-12b-it-ADDTOEXPNAME-f399f126-15c6af46_english_on_english/responses.json\"\n",
    "NUM_EXAMPLES = 5\n",
    "\n",
    "# === Load Responses ===\n",
    "with open(RESPONSES_PATH, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "    responses = json.load(f)\n",
    "\n",
    "print(f\"\\nðŸ” Loaded {len(responses)} responses. Showing first {NUM_EXAMPLES}:\\n\")\n",
    "\n",
    "# === Process First N Examples ===\n",
    "for i, example in enumerate(responses[:NUM_EXAMPLES]):\n",
    "    print(f\"\\n====== Example {i + 1} ======\\n\")\n",
    "    print(f\"ðŸ“ Sentence: {example['sentence']}\\n\")\n",
    "\n",
    "    raw_response = example[\"response\"]\n",
    "    print(f\"ðŸ”¹ Raw model output:\\n{raw_response}\\n\")\n",
    "\n",
    "    tokens = example[\"tokens\"]\n",
    "    gold_tags = example[\"labels\"]\n",
    "\n",
    "    # === Try to extract JSON and get idioms ===\n",
    "    import re\n",
    "\n",
    "    try:\n",
    "        match = re.search(r\"\\{[\\s\\S]*?\\}\", raw_response)\n",
    "        if match:\n",
    "            parsed = json.loads(match.group())\n",
    "            predicted_idioms = parsed.get(\"idioms\", [])\n",
    "            hallucinated = False\n",
    "        else:\n",
    "            print(\"âš ï¸ No valid JSON block found in response.\")\n",
    "            predicted_idioms = []\n",
    "            hallucinated = True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to parse model response: {e}\")\n",
    "        predicted_idioms = []\n",
    "        hallucinated = True\n",
    "\n",
    "    print(f\"âœ… Parsed idioms: {predicted_idioms}\\n\")\n",
    "\n",
    "    # === Convert to IOB ===\n",
    "    predicted_tags = idioms_list_to_IOB(predicted_idioms, tokens, hallucinated)\n",
    "\n",
    "    # === Display Side-by-Side Token Comparison ===\n",
    "    print(\"ðŸŸ¦ Token-by-token comparison:\")\n",
    "    print(\"{:<15} {:<12} {:<12}\".format(\"Token\", \"Gold\", \"Predicted\"))\n",
    "    print(\"-\" * 45)\n",
    "    for tok, gold, pred in zip(tokens, gold_tags, predicted_tags):\n",
    "        print(\"{:<15} {:<12} {:<12}\".format(tok.strip(), gold, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "18ab2097",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = \"```json\\n{\\n  \\\"idioms\\\": [\\n    \\\"broke the ice\\\"\\n  ]\\n}\\n```\"\n",
    "match = re.search(r\"\\{[\\s\\S]*?\\}\", answer)\n",
    "if match:\n",
    "    parsed = json.loads(match.group())\n",
    "    predicted_idioms = parsed.get(\"idioms\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fce99796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['broke the ice']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_idioms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9942da2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== Example 1 ======\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, example in enumerate(responses[:5]):\n",
    "    print (f\"\\n====== Example {i + 1} ======\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "819828f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fixed responses saved to: /Users/ofrihefetz/cross-lingual-idioms-1/gen_fine_tuning/logs/old promt/Meta-Llama-3.1-70B-Instruct-Reference-ADDTOEXPNAME-90df6b6f_english_on_english/responses.json\n",
      "âœ… New metrics saved to: /Users/ofrihefetz/cross-lingual-idioms-1/gen_fine_tuning/logs/old promt/Meta-Llama-3.1-70B-Instruct-Reference-ADDTOEXPNAME-90df6b6f_english_on_english/metrics.json\n",
      "\n",
      "ðŸ“Š Updated metrics:\n",
      "{'accuracy': 0.9263766352296927, 'precision': 0.7854693431126551, 'recall': 0.8579599496181297, 'f1': 0.8173350750606367}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "from src.gen_utils import idioms_list_to_IOB\n",
    "from in_context_learning.src.id10m_utils import LABELS\n",
    "from utils import calc_metrics_classification\n",
    "\n",
    "# === Paths ===\n",
    "RESPONSES_PATH = \"/Users/ofrihefetz/cross-lingual-idioms-1/gen_fine_tuning/logs/old promt/Meta-Llama-3.1-70B-Instruct-Reference-ADDTOEXPNAME-90df6b6f_english_on_english/responses.json\"\n",
    "METRICS_PATH = os.path.join(os.path.dirname(RESPONSES_PATH), \"metrics.json\")\n",
    "\n",
    "# === Load file ===\n",
    "with open(RESPONSES_PATH, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "    responses = json.load(f)\n",
    "\n",
    "updated_responses = []\n",
    "all_gold = []\n",
    "all_pred = []\n",
    "\n",
    "# === Fix each example ===\n",
    "for ex in responses:\n",
    "    tokens = ex[\"tokens\"]\n",
    "    labels = ex[\"labels\"]\n",
    "    response_text = ex[\"response\"]\n",
    "\n",
    "    try:\n",
    "        # Fix markdown JSON block\n",
    "        match = re.search(r\"\\{[\\s\\S]*?\\}\", response_text)\n",
    "        if match:\n",
    "            parsed = json.loads(match.group())\n",
    "            predicted_idioms = parsed.get(\"idioms\", [])\n",
    "            hallucinated = False\n",
    "        else:\n",
    "            predicted_idioms = []\n",
    "            hallucinated = True\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ JSON parsing failed for: {ex['sentence']}\")\n",
    "        predicted_idioms = []\n",
    "        hallucinated = True\n",
    "\n",
    "    predicted_tags = idioms_list_to_IOB(predicted_idioms, tokens, hallucinated)\n",
    "\n",
    "    ex[\"predicted_idioms\"] = predicted_idioms\n",
    "    ex[\"predicted_tags\"] = predicted_tags\n",
    "\n",
    "    updated_responses.append(ex)\n",
    "    all_gold.extend(labels)\n",
    "    all_pred.extend(predicted_tags)\n",
    "\n",
    "# === Save corrected responses ===\n",
    "with open(RESPONSES_PATH, \"w\", encoding=\"utf-8-sig\") as f:\n",
    "    json.dump(updated_responses, f, indent=2, ensure_ascii=False)\n",
    "print(f\"âœ… Fixed responses saved to: {RESPONSES_PATH}\")\n",
    "\n",
    "# === Compute new metrics ===\n",
    "metrics, _, _ = calc_metrics_classification(all_gold, all_pred, labels=LABELS)\n",
    "\n",
    "with open(METRICS_PATH, \"w\", encoding=\"utf-8-sig\") as f:\n",
    "    json.dump(metrics, f, indent=2, ensure_ascii=False)\n",
    "print(f\"âœ… New metrics saved to: {METRICS_PATH}\")\n",
    "print(f\"\\nðŸ“Š Updated metrics:\\n{metrics}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9deb4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file kfirbar--meta-llama-3.1-8b-instruct-reference-addtoexpname-b25f954f.tar.zst:   1%|â–         | 178M/12.5G [00:19<21:57, 9.32MB/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfine_tuning\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mft-d585489b-aef0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages/together/resources/finetune.py:684\u001b[39m, in \u001b[36mFineTuning.download\u001b[39m\u001b[34m(self, id, output, checkpoint_step, checkpoint_type)\u001b[39m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    682\u001b[39m     output = Path(output)\n\u001b[32m--> \u001b[39m\u001b[32m684\u001b[39m downloaded_filename, file_size = \u001b[43mdownload_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremote_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    686\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m FinetuneDownloadResult(\n\u001b[32m    689\u001b[39m     \u001b[38;5;28mobject\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mlocal\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    690\u001b[39m     \u001b[38;5;28mid\u001b[39m=\u001b[38;5;28mid\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    693\u001b[39m     size=file_size,\n\u001b[32m    694\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cross-lingual-idioms-1/.venv/lib/python3.13/site-packages/together/filemanager.py:227\u001b[39m, in \u001b[36mDownloadManager.download\u001b[39m\u001b[34m(self, url, output, remote_name, fetch_metadata)\u001b[39m\n\u001b[32m    225\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response.iter_content(DOWNLOAD_BLOCK_SIZE):\n\u001b[32m    226\u001b[39m             pbar.update(\u001b[38;5;28mlen\u001b[39m(chunk))\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m             \u001b[43mtemp_file\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[38;5;66;03m# Raise exception if remote file size does not match downloaded file size\u001b[39;00m\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.stat(temp_file.name).st_size != file_size:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.4/Frameworks/Python.framework/Versions/3.13/lib/python3.13/tempfile.py:499\u001b[39m, in \u001b[36m_TemporaryFileWrapper.__getattr__.<locals>.func_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    497\u001b[39m \u001b[38;5;129m@_functools\u001b[39m.wraps(func)\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunc_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m499\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "client.fine_tuning.download(id=\"ft_resp.id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319cbed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
