{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f17cc0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alon/miniconda3/envs/alon_cross_lingual_venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-20 19:50:04.485677 Start\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" #This should be before import of tokenizer. Note that EncoderTrainer imports tokenizer\n",
    "import sys\n",
    "import contextlib\n",
    "from transformers import BertForTokenClassification, AutoTokenizer\n",
    "import json\n",
    "from datetime import datetime \n",
    "import csv\n",
    "from pathlib import Path\n",
    "from encoder_trainer import EncoderTrainer\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass, field\n",
    "from typing import ClassVar, Tuple, Dict, List, Optional, Union\n",
    "import traceback\n",
    "from itertools import product\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from filelock import FileLock\n",
    "import functools\n",
    "\n",
    "\n",
    "# Get the project root directory\n",
    "current_dir = Path.cwd()\n",
    "project_root = current_dir.parent  # Go up one level from encoder_fine_tuning to cross-lingual-idioms\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from src.utils import get_data\n",
    "GPU = \"0\"\n",
    "EXECUTED_TESTS_FILE = \"executed_tests.json\"\n",
    "DEFAULT_RESULTS_FILE = \"unified_results.csv\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = GPU\n",
    "\n",
    "model_to_train_args = defaultdict(dict)\n",
    "model_to_train_args.update({\"FacebookAI/xlm-roberta-base\": {'learning_rate': 2e-05, 'per_device_train_batch_size': 8,\n",
    "                                                            'per_device_eval_batch_size': 8,  'lr_scheduler_type': 'linear'}})\n",
    "print(f\"{datetime.now()} Start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6afe063a-6f62-453d-84e2-7f7d106034e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_mutex(lock_path_func):\n",
    "    \"\"\"\n",
    "    Decorator to ensure file-based mutual exclusion (process and thread safe).\n",
    "    lock_path_func should return the path to the lock file and accept the same\n",
    "    arguments as the decorated function.\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            lock_path = lock_path_func(*args, **kwargs)\n",
    "            with FileLock(lock_path):\n",
    "                return func(*args, **kwargs)\n",
    "        return wrapper\n",
    "    return decorator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24adf784-2817-468a-a0f5-143cca71d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskConfig(Enum):\n",
    "    DODIOM = \"dodiom\"\n",
    "    ID10M = \"id10m\"\n",
    "    OPEN_MWE = \"open_mwe\"\n",
    "    MAGPIE = \"magpie\"\n",
    "\n",
    "LANGUAGE_TO_CODE: Dict[str, str] = {\n",
    "    \"english\": \"EN\",\n",
    "    \"spanish\": \"ES\",\n",
    "    \"german\": \"DE\",\n",
    "    \"japanese\": \"JP\",\n",
    "    \"turkish\": \"TR\",\n",
    "    \"chinese\": \"ZH\",\n",
    "    \"french\": \"FR\",\n",
    "    \"polish\": \"PL\",\n",
    "    \"italian\": \"IT\",\n",
    "    \"dutch\": \"NL\",\n",
    "    \"portuguese\": \"PT\"\n",
    "}\n",
    "    \n",
    "def get_language_map() -> Dict[str, str]:\n",
    "    \n",
    "    CODE_TO_LANGUAGE: Dict[str, str] = {v: k for k, v in LANGUAGE_TO_CODE.items()}\n",
    "    \n",
    "    # Merge into a single bidirectional object\n",
    "    return {**LANGUAGE_TO_CODE, **CODE_TO_LANGUAGE}\n",
    "\n",
    "LANGUAGE_MAP = get_language_map()\n",
    "\n",
    "@file_mutex(lambda directory_path, safe_model_name, decimal_round, output_csv_path: output_csv_path + \".lock\")\n",
    "def process_results_directory_to_csv(directory_path: str, safe_model_name: str, decimal_round: int , output_csv_path: str):\n",
    "    ordered_test_keys = [\n",
    "        \"EN_id10m\",\n",
    "        \"EN_magpie\",\n",
    "        \"DE_id10m\",\n",
    "        \"IT_id10m\",\n",
    "        \"IT_dodiom\",\n",
    "        \"ES_id10m\",\n",
    "        \"JP_open_mwe\",\n",
    "        \"TR_dodiom\"\n",
    "    ]\n",
    "    \n",
    "    valid_lang_codes = set(LANGUAGE_TO_CODE.values())\n",
    "    \n",
    "    # Regex to parse filenames\n",
    "    # Example filename: train_lang_zh_src_id10m_FacebookAI_xlm-roberta-base_seed_7.json\n",
    "    pattern = re.compile(\n",
    "        r\"train_lang_([a-z]{2})_src_([a-zA-Z0-9]+)_([a-zA-Z0-9_\\-]+)_seed_(\\d+)\\.json$\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    rows = []\n",
    "    all_keys = set()\n",
    "\n",
    "    for filename in os.listdir(directory_path):\n",
    "        match = pattern.match(filename)\n",
    "        if not match:\n",
    "            continue\n",
    "\n",
    "        train_lang, src, model_name, seed = match.groups()\n",
    "\n",
    "        if \"open_mwe\" in safe_model_name:\n",
    "            #Dirty workaround since mwe_ was incorrectly inserted as a prefix to the model name\n",
    "            src = \"open_mwe\"\n",
    "            model_name = model_name.replace(\"mwe_\", \"\")\n",
    "        \n",
    "        train_lang = train_lang.upper()\n",
    "        seed = int(seed)\n",
    "\n",
    "        # Check if train_lang is valid\n",
    "        if train_lang not in valid_lang_codes:\n",
    "            print(f\"{datetime.now()} Unknown train_lang {train_lang} Skipping\")\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            json_data = json.load(f)\n",
    "\n",
    "        # Find target language code in model name, if any\n",
    "        model_name_lower = model_name.lower()\n",
    "        model_languages = []\n",
    "        for lang_name, lang_code in LANGUAGE_TO_CODE.items():\n",
    "            if lang_name in model_name_lower:\n",
    "                model_languages.append(lang_code)\n",
    "                \n",
    "        # data is a dict like {\"EN_id10m\": {\"eval_f1\": 0.329}, ...}\n",
    "        # Extract keys and their metric values (assume single metric per key)\n",
    "        row = {\n",
    "            \"train_lang\": train_lang,\n",
    "            \"src\": src,\n",
    "            \"model_name\": model_name,\n",
    "            \"seed\": seed,\n",
    "        }\n",
    "\n",
    "        # Extract available metrics\n",
    "        available_metrics = {}\n",
    "        for key, metric_dict in json_data.items():\n",
    "            if isinstance(metric_dict, dict):\n",
    "                val = next(iter(metric_dict.values()))\n",
    "                if decimal_round>0:\n",
    "                    available_metrics[key] = round(float(val), decimal_round)\n",
    "                else:\n",
    "                    available_metrics[key] = float(val)\n",
    "\n",
    "        for test_key in ordered_test_keys:\n",
    "            if test_key in available_metrics:\n",
    "                row[test_key] = available_metrics[test_key]\n",
    "            else:\n",
    "                # Set -1 only if model is specialized (e.g., \"turkish\") and test_key is for another language\n",
    "                test_lang = test_key.split(\"_\")[0]  # e.g., EN from \"EN_id10m\"\n",
    "                if model_languages and test_lang not in model_languages:\n",
    "                    row[test_key] = -1\n",
    "                else:\n",
    "                    row[test_key] = \"\"\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    csv_columns = [\"train_lang\", \"src\", \"model_name\", \"seed\"] + ordered_test_keys\n",
    "\n",
    "    with open(output_csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        for row in rows:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(f\"{datetime.now()} CSV file saved to {output_csv_path}\")\n",
    "\n",
    "def general_process_results_directory_to_csv(directory_path: str, safe_model_name: str, output_csv_path: str):\n",
    "    name, ext = os.path.splitext(output_csv_path)\n",
    "    raw_output_csv_path = f\"{name}_raw{ext}\"\n",
    "    process_results_directory_to_csv(directory_path=directory_path, safe_model_name=safe_model_name, decimal_round=-1 , output_csv_path=raw_output_csv_path)\n",
    "    process_results_directory_to_csv(directory_path=directory_path, safe_model_name=safe_model_name, decimal_round=2 , output_csv_path=output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ef919d9-aabb-40ad-831b-8494c661da36",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class LanguageTestSetup:\n",
    "    \"\"\"\n",
    "    Represents a unique (language_code, source) test configuration.\n",
    "\n",
    "    Instances are created via the `get()` factory method, which ensures\n",
    "    that the same instance is reused for each (language_code, source) pair.\n",
    "    \"\"\"\n",
    "\n",
    "    language_code: str\n",
    "    source: str\n",
    "\n",
    "    # Internal cache to store/reuse instances\n",
    "    _instances: ClassVar[Dict[Tuple[str, str], \"LanguageTestSetup\"]] = {}\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # Ensure normalized uppercase language codes\n",
    "        if self.language_code != self.language_code.upper():\n",
    "            raise ValueError(\"language_code must be uppercase (e.g., 'EN')\")\n",
    "\n",
    "    @classmethod\n",
    "    def get(cls, language_code: str, source: str) -> \"LanguageTestSetup\":\n",
    "        \"\"\"\n",
    "        Factory method to return a cached instance based on input.\n",
    "        Ensures reuse and avoids duplicates.\n",
    "        \"\"\"\n",
    "        language_code = language_code.upper()\n",
    "        key = (language_code, source)\n",
    "        if key not in cls._instances:\n",
    "            instance = cls(language_code, source)\n",
    "            cls._instances[key] = instance\n",
    "        return cls._instances[key]\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.language_code}_{self.source}\"\n",
    "\n",
    "DEFAULT_TESTS: List[LanguageTestSetup] = [\n",
    "    LanguageTestSetup.get(\"EN\", TaskConfig.ID10M.value),\n",
    "    LanguageTestSetup.get(\"EN\", TaskConfig.MAGPIE.value),\n",
    "    LanguageTestSetup.get(\"DE\", TaskConfig.ID10M.value),\n",
    "    LanguageTestSetup.get(\"IT\", TaskConfig.ID10M.value),\n",
    "    LanguageTestSetup.get(\"IT\", TaskConfig.DODIOM.value),\n",
    "    LanguageTestSetup.get(\"ES\", TaskConfig.ID10M.value),\n",
    "    LanguageTestSetup.get(\"JP\", TaskConfig.OPEN_MWE.value),\n",
    "    LanguageTestSetup.get(\"TR\", TaskConfig.DODIOM.value),\n",
    "]\n",
    "\n",
    "def is_directory_empty(directory_path: Path):\n",
    "    \"\"\"\n",
    "    Returns True iff the directory is empty\n",
    "    \"\"\"\n",
    "    if not directory_path.is_dir():\n",
    "        return False \n",
    "    return not any(directory_path.iterdir())\n",
    "\n",
    "def get_only_default_tests_of_specific_language(lang: str) -> List[LanguageTestSetup]:\n",
    "    assert lang in LANGUAGE_TO_CODE, f\"Language name must be one of the following {list(LANGUAGE_TO_CODE.keys())} (case sensitive)\"\n",
    "    return [t for t in DEFAULT_TESTS if t.language_code == LANGUAGE_MAP[lang]]\n",
    "\n",
    "\n",
    "def is_huggingface_model_folder(folder: Path) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if the folder contains a minimal, ready-to-run Hugging Face model\n",
    "    (with config.json and model.safetensors), False otherwise.\n",
    "    \"\"\"\n",
    "    if not isinstance(folder, Path):\n",
    "        folder = Path(folder)\n",
    "    if not folder.is_dir():\n",
    "        return False\n",
    "\n",
    "    required_files = [\"config.json\", \"model.safetensors\"]\n",
    "    return all((folder / fname).is_file() for fname in required_files)\n",
    "\n",
    "def replace_separators_with_underscore(s):\n",
    "    \"\"\"Replaces all / and \\\\ in the string with _ in one pass.\"\"\"\n",
    "    return re.sub(r'[\\\\/]', '_', s)\n",
    "\n",
    "@dataclass\n",
    "class Test:\n",
    "    train_language: str  # e.g., \"english\"\n",
    "    source: str\n",
    "    model_name: str\n",
    "    safe_model_name: str #This is 'model_name' with slashes and backslashes replaced with an underscore (to use in paths)\n",
    "    results_dir: Path = Path(\"results\")\n",
    "    seed: int = -1\n",
    "    test_setups: List[LanguageTestSetup] = None\n",
    "    encoder_trainer: EncoderTrainer = field(default=None, repr=False)\n",
    "    train_out_path: Path = field(default=None, repr=False)\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        if 'results_dir' in kwargs:\n",
    "            self.results_dir = Path(kwargs.pop('results_dir'))\n",
    "        \n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "        self.safe_model_name = replace_separators_with_underscore(self.model_name)\n",
    "\n",
    "        if \"test_setups\" not in kwargs:\n",
    "            if self.train_language in self.model_name:\n",
    "                print(f\"Language {self.train_language} detected in model name {self.model_name} - thus only testing on this language. If you want to change this behavior, explictly set the variable test_setups\")\n",
    "                self.set_only_tests_of_train_language()\n",
    "            else:\n",
    "               self.test_setups = DEFAULT_TESTS\n",
    "\n",
    "        #Note this should be after setting relevant fields (e.g. train_language) otherwise __str_() would fail\n",
    "        if 'train_out_path' in kwargs:\n",
    "            self.train_out_path = Path(kwargs.pop('train_out_path'))\n",
    "        else:\n",
    "            self.update_train_out_path_to_default()\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        \"\"\"\n",
    "        Returns a string representation for the test.\n",
    "    \n",
    "        ⚠ Note:\n",
    "        - This is used, amongt other things, for storing file paths and checking execution.\n",
    "        \"\"\"\n",
    "        return f\"train_lang_{LANGUAGE_MAP[self.train_language].lower()}_src_{self.source}_{self.safe_model_name}_seed_{self.seed}\"\n",
    "        \n",
    "    def to_comparison_str(self):\n",
    "        \"\"\"\n",
    "        Returns a file-safe string identifier for the test.\n",
    "    \n",
    "        ⚠ Note:\n",
    "        - This is used for checking execution.\n",
    "        - Slashes and backslashes in `model_name` are replaced with underscores.\n",
    "        - Since the original model name cannot be perfectly recovered, this method should NOT be used for deserialization.\n",
    "        \"\"\"\n",
    "        return f\"{self.__str__()}_test_setups_{str(self.test_setups)}\"\n",
    "\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.__str__())\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, Test):\n",
    "            raise TypeError(\"Can only compare instances of same type\")\n",
    "        return self.to_comparison_str() == other.to_comparison_str()\n",
    "\n",
    "    def update_train_out_path_to_default(self):\n",
    "        self.train_out_path = Path(self.__str__())\n",
    "       \n",
    "    def set_only_tests_of_train_language(self):\n",
    "        self.test_setups =[t for t in DEFAULT_TESTS if t.language_code == LANGUAGE_MAP[self.train_language]]\n",
    "\n",
    "    def train(self, should_delete_checkpoints: bool = True):\n",
    "        assert self.seed>0, \"Need to set seed before calling train()\"\n",
    "        print(f\"{datetime.now()} Training gpu {GPU} {self}\")\n",
    "        data = get_data(lang=self.train_language, task=self.source)\n",
    "        train_data, test_data = data[\"train\"], data[\"test\"]\n",
    "        if test_data.empty:\n",
    "            print(f\"{datetime.now()} Got empty test dataset, using validation set instead\")\n",
    "            test_data = data[\"validation\"]\n",
    "\n",
    "        self.encoder_trainer = EncoderTrainer(\n",
    "            seed=self.seed,\n",
    "            model_name=self.model_name,\n",
    "            output_dir=self.train_out_path,\n",
    "            train_data=train_data,\n",
    "            test_data=test_data,\n",
    "            # data=data,\n",
    "            )\n",
    "        self.encoder_trainer.train(should_delete_checkpoints=should_delete_checkpoints, custom_train_args=model_to_train_args[self.model_name])\n",
    "\n",
    "    def test(self):\n",
    "        print(f\"{datetime.now()} Testing: {self.test_setups}\")\n",
    "        results = {}\n",
    "        for test_setup in self.test_setups:\n",
    "            try:\n",
    "                test_data = get_data(lang=LANGUAGE_MAP[test_setup.language_code], task=test_setup.source)[\"test\"]\n",
    "                results[str(test_setup)] = self.encoder_trainer.test(test_data=test_data, return_metrics=[\"eval_f1\"])\n",
    "            except Exception as e:\n",
    "                print(f\"{datetime.now()} An exception occurred in {test_setup}. {e}\\n{traceback.format_exc()}\")\n",
    "        \n",
    "        result_filename = f\"{self.__str__()}.json\" \n",
    "        try:\n",
    "            self.results_dir.mkdir(parents=True, exist_ok=True)\n",
    "            result_out_file_path = Path(self.results_dir, result_filename)\n",
    "        except Exception as e:\n",
    "            print(f\"{datetime.now()} An exception occurred while trying to create {self.results_dir}. Writing to local dir {os.getcwd()}. Exception: {e}\\n{traceback.format_exc()}\")\n",
    "            result_out_file_path = os.getcwd()\n",
    "        \n",
    "        print(f\"{datetime.now()} Saving results to {result_out_file_path}\")\n",
    "        with open(result_out_file_path, 'w') as f:\n",
    "            json.dump(results, f, indent=4)\n",
    "\n",
    "        general_process_results_directory_to_csv(str(self.results_dir), self.safe_model_name, DEFAULT_RESULTS_FILE)\n",
    "                \n",
    "    def set_existing_model(self):\n",
    "        #TODO - If keeping this, need to change because it's not alwys BertForTokenClassification (probably better to delete this logic all together, just don't check for existing models)\n",
    "        self.encoder_trainer = EncoderTrainer(\n",
    "            model_name=self.model_name,\n",
    "            trained_model=BertForTokenClassification.from_pretrained(self.train_out_path)\n",
    "            )\n",
    "\n",
    "    def run(self):\n",
    "        if self.test_setups is None:\n",
    "            if self.train_language in self.model_name:\n",
    "                print(f\"Language {self.train_language} detected in model name {self.model_name} - thus only testing on this language. If you want to change this behavior, explictly set the variable test_setups\")\n",
    "                self.set_only_tests_of_train_language()\n",
    "            else:\n",
    "               self.test_setups = DEFAULT_TESTS\n",
    "\n",
    "        print(f\"{datetime.now()} Running (gpu {GPU}) test {self}\")\n",
    "\n",
    "        if is_huggingface_model_folder(self.train_out_path):\n",
    "            print(f\"{datetime.now()} Found an existing model for this test, so skipping train. Model location: {self.train_out_path}\")\n",
    "            self.set_existing_model()\n",
    "        else:\n",
    "            self.train()\n",
    "        self.test()\n",
    "        if is_directory_empty(self.train_out_path):\n",
    "            os.rmdir(self.train_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b69820ad-d1c9-4bf0-8f85-b7d0333d3363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language german detected in model name google-bert/bert-base-german-cased - thus only testing on this language. If you want to change this behavior, explictly set the variable test_setups\n",
      "Language italian detected in model name dbmdz/bert-base-italian-cased - thus only testing on this language. If you want to change this behavior, explictly set the variable test_setups\n",
      "Language spanish detected in model name dccuchile/bert-base-spanish-wwm-cased - thus only testing on this language. If you want to change this behavior, explictly set the variable test_setups\n",
      "Language japanese detected in model name tohoku-nlp/bert-base-japanese - thus only testing on this language. If you want to change this behavior, explictly set the variable test_setups\n",
      "2025-07-20 19:50:04.536411 Loaded 157 executed tests\n",
      "2025-07-20 19:50:04.536612 Seed 1/5 Test 1/24\n",
      "2025-07-20 19:50:04.536661 Skipping test because already executed train_lang_en_src_magpie_FacebookAI_xlm-roberta-base_seed_5\n",
      "2025-07-20 19:50:04.536675 Seed 1/5 Test 2/24\n",
      "2025-07-20 19:50:04.536701 Skipping test because already executed train_lang_fr_src_id10m_FacebookAI_xlm-roberta-base_seed_5\n",
      "2025-07-20 19:50:04.536712 Seed 1/5 Test 3/24\n",
      "2025-07-20 19:50:04.536734 Skipping test because already executed train_lang_de_src_id10m_FacebookAI_xlm-roberta-base_seed_5\n",
      "2025-07-20 19:50:04.536744 Seed 1/5 Test 4/24\n",
      "2025-07-20 19:50:04.536761 Skipping test because already executed train_lang_it_src_id10m_dbmdz_bert-base-italian-cased_seed_5\n",
      "2025-07-20 19:50:04.536770 Seed 1/5 Test 5/24\n",
      "2025-07-20 19:50:04.536791 Skipping test because already executed train_lang_de_src_id10m_bert-base-multilingual-cased_seed_5\n",
      "2025-07-20 19:50:04.536801 Seed 1/5 Test 6/24\n",
      "2025-07-20 19:50:04.536817 Skipping test because already executed train_lang_es_src_id10m_dccuchile_bert-base-spanish-wwm-cased_seed_5\n",
      "2025-07-20 19:50:04.536827 Seed 1/5 Test 7/24\n",
      "2025-07-20 19:50:04.536846 Skipping test because already executed train_lang_pl_src_id10m_FacebookAI_xlm-roberta-base_seed_5\n",
      "2025-07-20 19:50:04.536857 Seed 1/5 Test 8/24\n",
      "2025-07-20 19:50:04.536878 Skipping test because already executed train_lang_it_src_id10m_bert-base-multilingual-cased_seed_5\n",
      "2025-07-20 19:50:04.536888 Seed 1/5 Test 9/24\n",
      "2025-07-20 19:50:04.536907 Skipping test because already executed train_lang_en_src_id10m_FacebookAI_xlm-roberta-base_seed_5\n",
      "2025-07-20 19:50:04.536917 Seed 1/5 Test 10/24\n",
      "2025-07-20 19:50:04.536937 Skipping test because already executed train_lang_fr_src_id10m_bert-base-multilingual-cased_seed_5\n",
      "2025-07-20 19:50:04.536946 Seed 1/5 Test 11/24\n",
      "2025-07-20 19:50:04.536965 Skipping test because already executed train_lang_pt_src_id10m_bert-base-multilingual-cased_seed_5\n",
      "2025-07-20 19:50:04.536974 Seed 1/5 Test 12/24\n",
      "2025-07-20 19:50:04.536992 Skipping test because already executed train_lang_pt_src_id10m_FacebookAI_xlm-roberta-base_seed_5\n",
      "2025-07-20 19:50:04.537003 Seed 1/5 Test 13/24\n",
      "2025-07-20 19:50:04.537018 Skipping test because already executed train_lang_en_src_id10m_FacebookAI_roberta-base_seed_5\n",
      "2025-07-20 19:50:04.537029 Seed 1/5 Test 14/24\n",
      "2025-07-20 19:50:04.537047 Skipping test because already executed train_lang_jp_src_open_mwe_FacebookAI_xlm-roberta-base_seed_5\n",
      "2025-07-20 19:50:04.537057 Seed 1/5 Test 15/24\n",
      "2025-07-20 19:50:04.537075 Skipping test because already executed train_lang_en_src_magpie_bert-base-multilingual-cased_seed_5\n",
      "2025-07-20 19:50:04.537085 Seed 1/5 Test 16/24\n",
      "2025-07-20 19:50:04.537103 Skipping test because already executed train_lang_pl_src_id10m_bert-base-multilingual-cased_seed_5\n",
      "2025-07-20 19:50:04.537112 Seed 1/5 Test 17/24\n",
      "2025-07-20 19:50:04.537127 Skipping test because already executed train_lang_en_src_magpie_FacebookAI_roberta-base_seed_5\n",
      "2025-07-20 19:50:04.537137 Seed 1/5 Test 18/24\n",
      "2025-07-20 19:50:04.537155 Skipping test because already executed train_lang_it_src_id10m_FacebookAI_xlm-roberta-base_seed_5\n",
      "2025-07-20 19:50:04.537164 Seed 1/5 Test 19/24\n",
      "2025-07-20 19:50:04.537182 Skipping test because already executed train_lang_es_src_id10m_bert-base-multilingual-cased_seed_5\n",
      "2025-07-20 19:50:04.537192 Seed 1/5 Test 20/24\n",
      "2025-07-20 19:50:04.537210 Skipping test because already executed train_lang_jp_src_open_mwe_bert-base-multilingual-cased_seed_5\n",
      "2025-07-20 19:50:04.537220 Seed 1/5 Test 21/24\n",
      "2025-07-20 19:50:04.537238 Skipping test because already executed train_lang_en_src_id10m_bert-base-multilingual-cased_seed_5\n",
      "2025-07-20 19:50:04.537248 Seed 1/5 Test 22/24\n",
      "2025-07-20 19:50:04.537263 Skipping test because already executed train_lang_de_src_id10m_google-bert_bert-base-german-cased_seed_5\n",
      "2025-07-20 19:50:04.537272 Seed 1/5 Test 23/24\n",
      "2025-07-20 19:50:04.537290 Skipping test because already executed train_lang_es_src_id10m_FacebookAI_xlm-roberta-base_seed_5\n",
      "2025-07-20 19:50:04.537300 Seed 1/5 Test 24/24\n",
      "2025-07-20 19:50:04.537313 Skipping test because already executed train_lang_jp_src_open_mwe_tohoku-nlp_bert-base-japanese_seed_5\n",
      "2025-07-20 19:50:04.537323 Seed 2/5 Test 1/24\n",
      "2025-07-20 19:50:04.537343 Skipping test because already executed train_lang_en_src_magpie_FacebookAI_xlm-roberta-base_seed_7\n",
      "2025-07-20 19:50:04.537353 Seed 2/5 Test 2/24\n",
      "2025-07-20 19:50:04.537371 Skipping test because already executed train_lang_fr_src_id10m_FacebookAI_xlm-roberta-base_seed_7\n",
      "2025-07-20 19:50:04.537381 Seed 2/5 Test 3/24\n",
      "2025-07-20 19:50:04.537400 Skipping test because already executed train_lang_de_src_id10m_FacebookAI_xlm-roberta-base_seed_7\n",
      "2025-07-20 19:50:04.537410 Seed 2/5 Test 4/24\n",
      "2025-07-20 19:50:04.537425 Skipping test because already executed train_lang_it_src_id10m_dbmdz_bert-base-italian-cased_seed_7\n",
      "2025-07-20 19:50:04.537435 Seed 2/5 Test 5/24\n",
      "2025-07-20 19:50:04.537453 Skipping test because already executed train_lang_de_src_id10m_bert-base-multilingual-cased_seed_7\n",
      "2025-07-20 19:50:04.537463 Seed 2/5 Test 6/24\n",
      "2025-07-20 19:50:04.537477 Skipping test because already executed train_lang_es_src_id10m_dccuchile_bert-base-spanish-wwm-cased_seed_7\n",
      "2025-07-20 19:50:04.537488 Seed 2/5 Test 7/24\n",
      "2025-07-20 19:50:04.537506 Skipping test because already executed train_lang_pl_src_id10m_FacebookAI_xlm-roberta-base_seed_7\n",
      "2025-07-20 19:50:04.537516 Seed 2/5 Test 8/24\n",
      "2025-07-20 19:50:04.537533 Skipping test because already executed train_lang_it_src_id10m_bert-base-multilingual-cased_seed_7\n",
      "2025-07-20 19:50:04.537543 Seed 2/5 Test 9/24\n",
      "2025-07-20 19:50:04.537560 Skipping test because already executed train_lang_en_src_id10m_FacebookAI_xlm-roberta-base_seed_7\n",
      "2025-07-20 19:50:04.537570 Seed 2/5 Test 10/24\n",
      "2025-07-20 19:50:04.537589 Skipping test because already executed train_lang_fr_src_id10m_bert-base-multilingual-cased_seed_7\n",
      "2025-07-20 19:50:04.537598 Seed 2/5 Test 11/24\n",
      "2025-07-20 19:50:04.537616 Skipping test because already executed train_lang_pt_src_id10m_bert-base-multilingual-cased_seed_7\n",
      "2025-07-20 19:50:04.537626 Seed 2/5 Test 12/24\n",
      "2025-07-20 19:50:04.537644 Skipping test because already executed train_lang_pt_src_id10m_FacebookAI_xlm-roberta-base_seed_7\n",
      "2025-07-20 19:50:04.537654 Seed 2/5 Test 13/24\n",
      "2025-07-20 19:50:04.537668 Skipping test because already executed train_lang_en_src_id10m_FacebookAI_roberta-base_seed_7\n",
      "2025-07-20 19:50:04.537678 Seed 2/5 Test 14/24\n",
      "2025-07-20 19:50:04.537696 Skipping test because already executed train_lang_jp_src_open_mwe_FacebookAI_xlm-roberta-base_seed_7\n",
      "2025-07-20 19:50:04.537705 Seed 2/5 Test 15/24\n",
      "2025-07-20 19:50:04.537723 Skipping test because already executed train_lang_en_src_magpie_bert-base-multilingual-cased_seed_7\n",
      "2025-07-20 19:50:04.537732 Seed 2/5 Test 16/24\n",
      "2025-07-20 19:50:04.537750 Skipping test because already executed train_lang_pl_src_id10m_bert-base-multilingual-cased_seed_7\n",
      "2025-07-20 19:50:04.537760 Seed 2/5 Test 17/24\n",
      "2025-07-20 19:50:04.537775 Skipping test because already executed train_lang_en_src_magpie_FacebookAI_roberta-base_seed_7\n",
      "2025-07-20 19:50:04.537784 Seed 2/5 Test 18/24\n",
      "2025-07-20 19:50:04.537802 Skipping test because already executed train_lang_it_src_id10m_FacebookAI_xlm-roberta-base_seed_7\n",
      "2025-07-20 19:50:04.537812 Seed 2/5 Test 19/24\n",
      "2025-07-20 19:50:04.537830 Skipping test because already executed train_lang_es_src_id10m_bert-base-multilingual-cased_seed_7\n",
      "2025-07-20 19:50:04.537840 Seed 2/5 Test 20/24\n",
      "2025-07-20 19:50:04.537858 Skipping test because already executed train_lang_jp_src_open_mwe_bert-base-multilingual-cased_seed_7\n",
      "2025-07-20 19:50:04.537867 Seed 2/5 Test 21/24\n",
      "2025-07-20 19:50:04.537885 Skipping test because already executed train_lang_en_src_id10m_bert-base-multilingual-cased_seed_7\n",
      "2025-07-20 19:50:04.537895 Seed 2/5 Test 22/24\n",
      "2025-07-20 19:50:04.537908 Skipping test because already executed train_lang_de_src_id10m_google-bert_bert-base-german-cased_seed_7\n",
      "2025-07-20 19:50:04.537918 Seed 2/5 Test 23/24\n",
      "2025-07-20 19:50:04.537937 Skipping test because already executed train_lang_es_src_id10m_FacebookAI_xlm-roberta-base_seed_7\n",
      "2025-07-20 19:50:04.537947 Seed 2/5 Test 24/24\n",
      "2025-07-20 19:50:04.537961 Skipping test because already executed train_lang_jp_src_open_mwe_tohoku-nlp_bert-base-japanese_seed_7\n",
      "2025-07-20 19:50:04.537971 Seed 3/5 Test 1/24\n",
      "2025-07-20 19:50:04.538000 Skipping test because already executed train_lang_en_src_magpie_FacebookAI_xlm-roberta-base_seed_42\n",
      "2025-07-20 19:50:04.538009 Seed 3/5 Test 2/24\n",
      "2025-07-20 19:50:04.538027 Skipping test because already executed train_lang_fr_src_id10m_FacebookAI_xlm-roberta-base_seed_42\n",
      "2025-07-20 19:50:04.538036 Seed 3/5 Test 3/24\n",
      "2025-07-20 19:50:04.538054 Skipping test because already executed train_lang_de_src_id10m_FacebookAI_xlm-roberta-base_seed_42\n",
      "2025-07-20 19:50:04.538063 Seed 3/5 Test 4/24\n",
      "2025-07-20 19:50:04.538078 Skipping test because already executed train_lang_it_src_id10m_dbmdz_bert-base-italian-cased_seed_42\n",
      "2025-07-20 19:50:04.538087 Seed 3/5 Test 5/24\n",
      "2025-07-20 19:50:04.538105 Skipping test because already executed train_lang_de_src_id10m_bert-base-multilingual-cased_seed_42\n",
      "2025-07-20 19:50:04.538115 Seed 3/5 Test 6/24\n",
      "2025-07-20 19:50:04.538128 Skipping test because already executed train_lang_es_src_id10m_dccuchile_bert-base-spanish-wwm-cased_seed_42\n",
      "2025-07-20 19:50:04.538138 Seed 3/5 Test 7/24\n",
      "2025-07-20 19:50:04.538155 Skipping test because already executed train_lang_pl_src_id10m_FacebookAI_xlm-roberta-base_seed_42\n",
      "2025-07-20 19:50:04.538164 Seed 3/5 Test 8/24\n",
      "2025-07-20 19:50:04.538182 Skipping test because already executed train_lang_it_src_id10m_bert-base-multilingual-cased_seed_42\n",
      "2025-07-20 19:50:04.538191 Seed 3/5 Test 9/24\n",
      "2025-07-20 19:50:04.538209 Skipping test because already executed train_lang_en_src_id10m_FacebookAI_xlm-roberta-base_seed_42\n",
      "2025-07-20 19:50:04.538218 Seed 3/5 Test 10/24\n",
      "2025-07-20 19:50:04.538236 Skipping test because already executed train_lang_fr_src_id10m_bert-base-multilingual-cased_seed_42\n",
      "2025-07-20 19:50:04.538245 Seed 3/5 Test 11/24\n",
      "2025-07-20 19:50:04.538263 Skipping test because already executed train_lang_pt_src_id10m_bert-base-multilingual-cased_seed_42\n",
      "2025-07-20 19:50:04.538272 Seed 3/5 Test 12/24\n",
      "2025-07-20 19:50:04.538292 Skipping test because already executed train_lang_pt_src_id10m_FacebookAI_xlm-roberta-base_seed_42\n",
      "2025-07-20 19:50:04.538302 Seed 3/5 Test 13/24\n",
      "2025-07-20 19:50:04.538316 Skipping test because already executed train_lang_en_src_id10m_FacebookAI_roberta-base_seed_42\n",
      "2025-07-20 19:50:04.538326 Seed 3/5 Test 14/24\n",
      "2025-07-20 19:50:04.538343 Skipping test because already executed train_lang_jp_src_open_mwe_FacebookAI_xlm-roberta-base_seed_42\n",
      "2025-07-20 19:50:04.538353 Seed 3/5 Test 15/24\n",
      "2025-07-20 19:50:04.538371 Skipping test because already executed train_lang_en_src_magpie_bert-base-multilingual-cased_seed_42\n",
      "2025-07-20 19:50:04.538380 Seed 3/5 Test 16/24\n",
      "2025-07-20 19:50:04.538398 Skipping test because already executed train_lang_pl_src_id10m_bert-base-multilingual-cased_seed_42\n",
      "2025-07-20 19:50:04.538408 Seed 3/5 Test 17/24\n",
      "2025-07-20 19:50:04.538422 Skipping test because already executed train_lang_en_src_magpie_FacebookAI_roberta-base_seed_42\n",
      "2025-07-20 19:50:04.538431 Seed 3/5 Test 18/24\n",
      "2025-07-20 19:50:04.538473 Skipping test because already executed train_lang_it_src_id10m_FacebookAI_xlm-roberta-base_seed_42\n",
      "2025-07-20 19:50:04.538483 Seed 3/5 Test 19/24\n",
      "2025-07-20 19:50:04.538501 Skipping test because already executed train_lang_es_src_id10m_bert-base-multilingual-cased_seed_42\n",
      "2025-07-20 19:50:04.538511 Seed 3/5 Test 20/24\n",
      "2025-07-20 19:50:04.538529 Skipping test because already executed train_lang_jp_src_open_mwe_bert-base-multilingual-cased_seed_42\n",
      "2025-07-20 19:50:04.538539 Seed 3/5 Test 21/24\n",
      "2025-07-20 19:50:04.538562 Skipping test because already executed train_lang_en_src_id10m_bert-base-multilingual-cased_seed_42\n",
      "2025-07-20 19:50:04.538571 Seed 3/5 Test 22/24\n",
      "2025-07-20 19:50:04.538586 Skipping test because already executed train_lang_de_src_id10m_google-bert_bert-base-german-cased_seed_42\n",
      "2025-07-20 19:50:04.538595 Seed 3/5 Test 23/24\n",
      "2025-07-20 19:50:04.538613 Skipping test because already executed train_lang_es_src_id10m_FacebookAI_xlm-roberta-base_seed_42\n",
      "2025-07-20 19:50:04.538623 Seed 3/5 Test 24/24\n",
      "2025-07-20 19:50:04.538637 Skipping test because already executed train_lang_jp_src_open_mwe_tohoku-nlp_bert-base-japanese_seed_42\n",
      "2025-07-20 19:50:04.538647 Seed 4/5 Test 1/24\n",
      "2025-07-20 19:50:04.538665 Skipping test because already executed train_lang_en_src_magpie_FacebookAI_xlm-roberta-base_seed_123\n",
      "2025-07-20 19:50:04.538675 Seed 4/5 Test 2/24\n",
      "2025-07-20 19:50:04.538692 Skipping test because already executed train_lang_fr_src_id10m_FacebookAI_xlm-roberta-base_seed_123\n",
      "2025-07-20 19:50:04.538702 Seed 4/5 Test 3/24\n",
      "2025-07-20 19:50:04.538720 Skipping test because already executed train_lang_de_src_id10m_FacebookAI_xlm-roberta-base_seed_123\n",
      "2025-07-20 19:50:04.538730 Seed 4/5 Test 4/24\n",
      "2025-07-20 19:50:04.538745 Skipping test because already executed train_lang_it_src_id10m_dbmdz_bert-base-italian-cased_seed_123\n",
      "2025-07-20 19:50:04.538754 Seed 4/5 Test 5/24\n",
      "2025-07-20 19:50:04.538772 Skipping test because already executed train_lang_de_src_id10m_bert-base-multilingual-cased_seed_123\n",
      "2025-07-20 19:50:04.538782 Seed 4/5 Test 6/24\n",
      "2025-07-20 19:50:04.538797 Skipping test because already executed train_lang_es_src_id10m_dccuchile_bert-base-spanish-wwm-cased_seed_123\n",
      "2025-07-20 19:50:04.538806 Seed 4/5 Test 7/24\n",
      "2025-07-20 19:50:04.538824 Skipping test because already executed train_lang_pl_src_id10m_FacebookAI_xlm-roberta-base_seed_123\n",
      "2025-07-20 19:50:04.538834 Seed 4/5 Test 8/24\n",
      "2025-07-20 19:50:04.538853 Skipping test because already executed train_lang_it_src_id10m_bert-base-multilingual-cased_seed_123\n",
      "2025-07-20 19:50:04.538863 Seed 4/5 Test 9/24\n",
      "2025-07-20 19:50:04.538881 Skipping test because already executed train_lang_en_src_id10m_FacebookAI_xlm-roberta-base_seed_123\n",
      "2025-07-20 19:50:04.538891 Seed 4/5 Test 10/24\n",
      "2025-07-20 19:50:04.538909 Skipping test because already executed train_lang_fr_src_id10m_bert-base-multilingual-cased_seed_123\n",
      "2025-07-20 19:50:04.538919 Seed 4/5 Test 11/24\n",
      "2025-07-20 19:50:04.538937 Skipping test because already executed train_lang_pt_src_id10m_bert-base-multilingual-cased_seed_123\n",
      "2025-07-20 19:50:04.538947 Seed 4/5 Test 12/24\n",
      "2025-07-20 19:50:04.538965 Skipping test because already executed train_lang_pt_src_id10m_FacebookAI_xlm-roberta-base_seed_123\n",
      "2025-07-20 19:50:04.538975 Seed 4/5 Test 13/24\n",
      "2025-07-20 19:50:04.538989 Skipping test because already executed train_lang_en_src_id10m_FacebookAI_roberta-base_seed_123\n",
      "2025-07-20 19:50:04.538999 Seed 4/5 Test 14/24\n",
      "2025-07-20 19:50:04.539017 Skipping test because already executed train_lang_jp_src_open_mwe_FacebookAI_xlm-roberta-base_seed_123\n",
      "2025-07-20 19:50:04.539027 Seed 4/5 Test 15/24\n",
      "2025-07-20 19:50:04.539045 Skipping test because already executed train_lang_en_src_magpie_bert-base-multilingual-cased_seed_123\n",
      "2025-07-20 19:50:04.539055 Seed 4/5 Test 16/24\n",
      "2025-07-20 19:50:04.539073 Skipping test because already executed train_lang_pl_src_id10m_bert-base-multilingual-cased_seed_123\n",
      "2025-07-20 19:50:04.539083 Seed 4/5 Test 17/24\n",
      "2025-07-20 19:50:04.539097 Skipping test because already executed train_lang_en_src_magpie_FacebookAI_roberta-base_seed_123\n",
      "2025-07-20 19:50:04.539107 Seed 4/5 Test 18/24\n",
      "2025-07-20 19:50:04.539125 Skipping test because already executed train_lang_it_src_id10m_FacebookAI_xlm-roberta-base_seed_123\n",
      "2025-07-20 19:50:04.539135 Seed 4/5 Test 19/24\n",
      "2025-07-20 19:50:04.539153 Skipping test because already executed train_lang_es_src_id10m_bert-base-multilingual-cased_seed_123\n",
      "2025-07-20 19:50:04.539163 Seed 4/5 Test 20/24\n",
      "2025-07-20 19:50:04.539181 Skipping test because already executed train_lang_jp_src_open_mwe_bert-base-multilingual-cased_seed_123\n",
      "2025-07-20 19:50:04.539191 Seed 4/5 Test 21/24\n",
      "2025-07-20 19:50:04.539210 Skipping test because already executed train_lang_en_src_id10m_bert-base-multilingual-cased_seed_123\n",
      "2025-07-20 19:50:04.539220 Seed 4/5 Test 22/24\n",
      "2025-07-20 19:50:04.539234 Skipping test because already executed train_lang_de_src_id10m_google-bert_bert-base-german-cased_seed_123\n",
      "2025-07-20 19:50:04.539244 Seed 4/5 Test 23/24\n",
      "2025-07-20 19:50:04.539262 Skipping test because already executed train_lang_es_src_id10m_FacebookAI_xlm-roberta-base_seed_123\n",
      "2025-07-20 19:50:04.539272 Seed 4/5 Test 24/24\n",
      "2025-07-20 19:50:04.539287 Skipping test because already executed train_lang_jp_src_open_mwe_tohoku-nlp_bert-base-japanese_seed_123\n",
      "2025-07-20 19:50:04.539297 Seed 5/5 Test 1/24\n",
      "2025-07-20 19:50:04.539316 Skipping test because already executed train_lang_en_src_magpie_FacebookAI_xlm-roberta-base_seed_1773\n",
      "2025-07-20 19:50:04.539326 Seed 5/5 Test 2/24\n",
      "2025-07-20 19:50:04.539345 Skipping test because already executed train_lang_fr_src_id10m_FacebookAI_xlm-roberta-base_seed_1773\n",
      "2025-07-20 19:50:04.539355 Seed 5/5 Test 3/24\n",
      "2025-07-20 19:50:04.539373 Skipping test because already executed train_lang_de_src_id10m_FacebookAI_xlm-roberta-base_seed_1773\n",
      "2025-07-20 19:50:04.539384 Seed 5/5 Test 4/24\n",
      "2025-07-20 19:50:04.539398 Skipping test because already executed train_lang_it_src_id10m_dbmdz_bert-base-italian-cased_seed_1773\n",
      "2025-07-20 19:50:04.539408 Seed 5/5 Test 5/24\n",
      "2025-07-20 19:50:04.539427 Skipping test because already executed train_lang_de_src_id10m_bert-base-multilingual-cased_seed_1773\n",
      "2025-07-20 19:50:04.539437 Seed 5/5 Test 6/24\n",
      "2025-07-20 19:50:04.539451 Skipping test because already executed train_lang_es_src_id10m_dccuchile_bert-base-spanish-wwm-cased_seed_1773\n",
      "2025-07-20 19:50:04.539461 Seed 5/5 Test 7/24\n",
      "2025-07-20 19:50:04.539479 Skipping test because already executed train_lang_pl_src_id10m_FacebookAI_xlm-roberta-base_seed_1773\n",
      "2025-07-20 19:50:04.539489 Seed 5/5 Test 8/24\n",
      "2025-07-20 19:50:04.539507 Skipping test because already executed train_lang_it_src_id10m_bert-base-multilingual-cased_seed_1773\n",
      "2025-07-20 19:50:04.539517 Seed 5/5 Test 9/24\n",
      "2025-07-20 19:50:04.539536 Skipping test because already executed train_lang_en_src_id10m_FacebookAI_xlm-roberta-base_seed_1773\n",
      "2025-07-20 19:50:04.539546 Seed 5/5 Test 10/24\n",
      "2025-07-20 19:50:04.539564 Skipping test because already executed train_lang_fr_src_id10m_bert-base-multilingual-cased_seed_1773\n",
      "2025-07-20 19:50:04.539574 Seed 5/5 Test 11/24\n",
      "2025-07-20 19:50:04.539592 Skipping test because already executed train_lang_pt_src_id10m_bert-base-multilingual-cased_seed_1773\n",
      "2025-07-20 19:50:04.539602 Seed 5/5 Test 12/24\n",
      "2025-07-20 19:50:04.539620 Skipping test because already executed train_lang_pt_src_id10m_FacebookAI_xlm-roberta-base_seed_1773\n",
      "2025-07-20 19:50:04.539630 Seed 5/5 Test 13/24\n",
      "2025-07-20 19:50:04.539644 Skipping test because already executed train_lang_en_src_id10m_FacebookAI_roberta-base_seed_1773\n",
      "2025-07-20 19:50:04.539654 Seed 5/5 Test 14/24\n",
      "2025-07-20 19:50:04.539673 Skipping test because already executed train_lang_jp_src_open_mwe_FacebookAI_xlm-roberta-base_seed_1773\n",
      "2025-07-20 19:50:04.539683 Seed 5/5 Test 15/24\n",
      "2025-07-20 19:50:04.539701 Skipping test because already executed train_lang_en_src_magpie_bert-base-multilingual-cased_seed_1773\n",
      "2025-07-20 19:50:04.539711 Seed 5/5 Test 16/24\n",
      "2025-07-20 19:50:04.539730 Skipping test because already executed train_lang_pl_src_id10m_bert-base-multilingual-cased_seed_1773\n",
      "2025-07-20 19:50:04.539740 Seed 5/5 Test 17/24\n",
      "2025-07-20 19:50:04.539754 Skipping test because already executed train_lang_en_src_magpie_FacebookAI_roberta-base_seed_1773\n",
      "2025-07-20 19:50:04.539775 Seed 5/5 Test 18/24\n",
      "2025-07-20 19:50:04.539793 Skipping test because already executed train_lang_it_src_id10m_FacebookAI_xlm-roberta-base_seed_1773\n",
      "2025-07-20 19:50:04.539803 Seed 5/5 Test 19/24\n",
      "2025-07-20 19:50:04.539821 Skipping test because already executed train_lang_es_src_id10m_bert-base-multilingual-cased_seed_1773\n",
      "2025-07-20 19:50:04.539831 Seed 5/5 Test 20/24\n",
      "2025-07-20 19:50:04.539850 Skipping test because already executed train_lang_jp_src_open_mwe_bert-base-multilingual-cased_seed_1773\n",
      "2025-07-20 19:50:04.539860 Seed 5/5 Test 21/24\n",
      "2025-07-20 19:50:04.539880 Skipping test because already executed train_lang_en_src_id10m_bert-base-multilingual-cased_seed_1773\n",
      "2025-07-20 19:50:04.539890 Seed 5/5 Test 22/24\n",
      "2025-07-20 19:50:04.539904 Skipping test because already executed train_lang_de_src_id10m_google-bert_bert-base-german-cased_seed_1773\n",
      "2025-07-20 19:50:04.539913 Seed 5/5 Test 23/24\n",
      "2025-07-20 19:50:04.539931 Skipping test because already executed train_lang_es_src_id10m_FacebookAI_xlm-roberta-base_seed_1773\n",
      "2025-07-20 19:50:04.539941 Seed 5/5 Test 24/24\n",
      "2025-07-20 19:50:04.539954 Skipping test because already executed train_lang_jp_src_open_mwe_tohoku-nlp_bert-base-japanese_seed_1773\n"
     ]
    }
   ],
   "source": [
    "@file_mutex(lambda: EXECUTED_TESTS_FILE + \".lock\")\n",
    "def get_executed_tests_ids() -> set[str]:\n",
    "    \"\"\"\n",
    "    Loads previously executed Test instances from disk\n",
    "    Returns an empty set if the file does not exist.\n",
    "    \"\"\"\n",
    "    executed_tests_file_type_path = Path(EXECUTED_TESTS_FILE)\n",
    "    if executed_tests_file_type_path.exists():\n",
    "        return set(json.loads(executed_tests_file_type_path.read_text()))\n",
    "    return set()\n",
    "\n",
    "def save_executed_tests(executed_tests_ids: set[str]):\n",
    "    \"\"\"\n",
    "    Saves the current set of executed Test ids to disk.\n",
    "    \"\"\"\n",
    "    executed_tests_file_type_path = Path(EXECUTED_TESTS_FILE)\n",
    "    executed_tests_file_type_path.write_text(json.dumps(list(executed_tests_ids), indent=2))\n",
    "\n",
    "@file_mutex(lambda *args, **kwargs: EXECUTED_TESTS_FILE + \".lock\")\n",
    "def add_test_to_executed(cur_test: Test, executed_tests_ids: set[str]):\n",
    "    executed_tests_ids.add(cur_test.to_comparison_str())\n",
    "    save_executed_tests(executed_tests_ids)\n",
    "\n",
    "def was_test_executed(cur_test: Test, executed_tests_ids: set[str]) -> bool:\n",
    "    return cur_test.to_comparison_str() in executed_tests_ids\n",
    "\n",
    "SEEDS = [5, 7, 42, 123, 1773]\n",
    "EN_TESTS = set([Test(train_language=\"english\", source=src, model_name=m)\n",
    "                for src, m in product([TaskConfig.ID10M.value, TaskConfig.MAGPIE.value],\n",
    "                                               [\"bert-base-multilingual-cased\", \"FacebookAI/xlm-roberta-base\"])])\n",
    "EN_TESTS.update(set([Test(train_language=\"english\", source=src, model_name=\"FacebookAI/roberta-base\",\n",
    "                test_setups = get_only_default_tests_of_specific_language(\"english\")) for src in [TaskConfig.ID10M.value, TaskConfig.MAGPIE.value]]))\n",
    "\n",
    "DE_TESTS = set([Test(train_language=\"german\", source=TaskConfig.ID10M.value, model_name=m) for m in \n",
    "                [\"bert-base-multilingual-cased\", \"FacebookAI/xlm-roberta-base\", \"google-bert/bert-base-german-cased\"]])\n",
    "\n",
    "# We stopped using DODIOM after surveying early results, keeping it commented for now. need to delete in the future\n",
    "# IT_TESTS = set([Test(train_language=\"italian\", source=src, model_name=m)\n",
    "#                 for src, m in product([TaskConfig.ID10M.value, TaskConfig.DODIOM.value],\n",
    "#                                       [\"bert-base-multilingual-cased\", \"FacebookAI/xlm-roberta-base\", \"dbmdz/bert-base-italian-cased\"])])\n",
    "\n",
    "IT_TESTS = set([Test(train_language=\"italian\", source=TaskConfig.ID10M.value, model_name=m)\n",
    "                for m in [\"bert-base-multilingual-cased\", \"FacebookAI/xlm-roberta-base\", \"dbmdz/bert-base-italian-cased\"]])\n",
    "\n",
    "ES_TESTS = set([Test(train_language=\"spanish\", source=TaskConfig.ID10M.value, model_name=m)\n",
    "                for m in [\"bert-base-multilingual-cased\", \"FacebookAI/xlm-roberta-base\", \"dccuchile/bert-base-spanish-wwm-cased\"]])\n",
    "\n",
    "# We stopped using JP (IDIOM) after surveying early\n",
    "JP_TESTS = set([Test(train_language=\"japanese\", source=TaskConfig.OPEN_MWE.value, model_name=m)\n",
    "                for m in [\"bert-base-multilingual-cased\", \"FacebookAI/xlm-roberta-base\", \"tohoku-nlp/bert-base-japanese\"]])\n",
    "\n",
    "# We stopped using DODIOM after surveying early results, keeping it commented for now. need to delete in the future\n",
    "# TR_TESTS = set([Test(train_language=\"turkish\", source=TaskConfig.DODIOM.value, model_name=m)\n",
    "#                 for m in [\"bert-base-multilingual-cased\", \"FacebookAI/xlm-roberta-base\", \"dbmdz/bert-base-turkish-cased\"]])\n",
    "\n",
    "#Languages we dropped due to early results: dutch, chinese,\n",
    "OTHER_TESTS = set([Test(train_language=lang, source=TaskConfig.ID10M.value, model_name=m)\n",
    "                for lang, m in product([\"french\", \"polish\", \"portuguese\"],\n",
    "                                      [\"bert-base-multilingual-cased\", \"FacebookAI/xlm-roberta-base\"])])\n",
    "\n",
    " \n",
    "TESTS = set()\n",
    "TESTS.update(EN_TESTS, JP_TESTS, IT_TESTS, ES_TESTS, DE_TESTS, OTHER_TESTS)#) # TR_TESTS\n",
    "\n",
    "\n",
    "executed_tests_ids = get_executed_tests_ids()\n",
    "print(f\"{datetime.now()} Loaded {len(executed_tests_ids)} executed tests\")\n",
    "failed_tests = []\n",
    "\n",
    "tests_to_run = TESTS\n",
    "for i_seed, cur_seed in enumerate(SEEDS):\n",
    "    for i_tst, cur_test in enumerate(tests_to_run):\n",
    "        print(f\"{datetime.now()} Seed {i_seed+1}/{len(SEEDS)} Test {i_tst+1}/{len(tests_to_run)}\")\n",
    "        cur_test.seed = cur_seed\n",
    "        cur_test.update_train_out_path_to_default()\n",
    "        if was_test_executed(cur_test, executed_tests_ids):\n",
    "            print(f\"{datetime.now()} Skipping test because already executed {cur_test}\")\n",
    "            continue\n",
    "        try:\n",
    "            cur_test.run()\n",
    "            add_test_to_executed(cur_test, executed_tests_ids)\n",
    "        except Exception as e:\n",
    "            print(f\"{datetime.now()} An exception occurred in {cur_test}. {e}\\n{traceback.format_exc()}\")\n",
    "            failed_tests.append(cur_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ba76b5b-38ff-4695-a838-e206e242f2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-20 19:50:04.544218 0 Tests failed\n"
     ]
    }
   ],
   "source": [
    "print(f\"{datetime.now()} {len(failed_tests)} Tests failed\")\n",
    "if len(failed_tests)>0:\n",
    "    print(f\"Failed tests: {failed_tests}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beaaa683-cf8d-4301-94d9-f9aa79e19dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-20 19:50:04.548377 FIN\n"
     ]
    }
   ],
   "source": [
    "print(f\"{datetime.now()} FIN\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
